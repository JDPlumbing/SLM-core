
# ğŸ§  SLM-core v3.0.0

**Structured Language Model (SLM)** â€” a compact, slot-based encoder for translating fuzzy human input into machine-readable bytecode.

Built for field logs, trust protocols, and structured AI inference.

---

## ğŸš€ What It Does

SLM v3 takes messy, natural language like:

```
"Installed red toilet upstairs due to leak"
```

...and turns it into a tightly packed 32-byte hexcode:

```
000a060000c20000000000000000510000000000000000000000000000002d
```

That hexcode maps to 16 structured slots like:

```json
{
  "verb": "installed",
  "object": "toilet",
  "color": "red",
  "adverb": "upstairs",
  "cause": "leak"
}
```

...and renders clean output like:

```
Installed red toilet upstairs due to leak.
```

---

## ğŸ“¦ Project Layout

```
SLM-core/
â”œâ”€â”€ v3/
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ encoder.py          # Slot â†’ bytecode
â”‚   â”‚   â”œâ”€â”€ decoder.py          # Bytecode â†’ slot
â”‚   â”‚   â”œâ”€â”€ renderer_en.py      # Slot â†’ natural English
â”‚   â”‚   â”œâ”€â”€ slm_tokenizer.py    # Token â†’ slot (via dictionaries)
â”‚   â”‚   â”œâ”€â”€ slm_normalizer.py   # Fuzzy spell-correction + preprocessing
â”‚   â”‚   â””â”€â”€ dictionaries.py     # Loads all dicts into usable maps
â”‚   â”œâ”€â”€ dict/
â”‚   â”‚   â”œâ”€â”€ verbs.json
â”‚   â”‚   â”œâ”€â”€ objects.json
â”‚   â”‚   â”œâ”€â”€ (etc... 16 total)
â”‚   â”œâ”€â”€ slm_cli.py              # Playground CLI
â”‚   â””â”€â”€ README.md
```

---

## ğŸ§© 16 Semantic Slots

Each natural-language statement is parsed into **16 slots**, each with a fixed byte-width.

| Slot Name    | Bytes | Example           |
|--------------|-------|-------------------|
| `verb`       | 3     | install           |
| `object`     | 3     | toilet            |
| `subject`    | 2     | plumber           |
| `size`       | 2     | 1in               |
| `material`   | 2     | copper            |
| `shape`      | 2     | round             |
| `color`      | 1     | red               |
| `condition`  | 1     | new               |
| `purpose`    | 2     | upgrade           |
| `preposition`| 1     | under             |
| `adjective`  | 2     | broken            |
| `adverb`     | 2     | upstairs          |
| `status`     | 1     | complete          |
| `cause`      | 3     | leak              |
| `intent`     | 3     | replace           |
| `space`      | 2     | bathroom          |

---

## ğŸ§ª Try It Locally

Run the CLI:

```bash
cd SLM-core/v3
python3 slm_cli.py
```

Then enter fuzzy phrases like:

```
>>> installd copperr toileet bathroom
```

SLM will:
1. Normalize spelling (`installed`, `copper`, `toilet`)
2. Tokenize into slots
3. Encode to hex
4. Decode back to slots
5. Render into a readable sentence

---

## âš™ï¸ Dictionaries

All slot values live in `dict/` as JSON files. Each key is a hexcode, each value is a lowercase word.

Example `verbs.json`:

```json
{
  "000001": "install",
  "000002": "remove",
  "000003": "inspect"
}
```

Want to add words? Just expand the dicts â€” no retraining or retriggering needed.

---

## ğŸ’¡ Design Philosophy

- **Human in, byte out.**
- Fast, fixed-width slot schema (no fluff).
- Zero AI needed to decode â€” works offline.
- GPT-friendly: small enough to pass as tokens, structured enough to prompt.

---

## ğŸ›£ï¸ Roadmap

- [x] Fuzzy normalization (`copperr` â†’ `copper`)
- [x] 16-slot architecture complete
- [ ] Contextual inference for conflicting tokens (e.g. `leak` as cause vs. object)
- [ ] Event/chaincode integration
- [ ] GUI playground / mobile app

---

## ğŸ§  Credits

Created by JD of JD Plumbing SoFlo  
Powered by domain-first logic, not NLP spaghetti.

---

## ğŸ”– License

MIT, or possibly Just Don't Be Evil.
